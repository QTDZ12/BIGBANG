# 分布数计算框架MapReduce(预习)

[TOC]

​           MapReduce 是一种用于在大型商用硬件集群中（成千上万的结点）对海量数据（多个兆字节数据集）实施可靠的、高容错的分布式计算的框架，也是一种经典的并行计算模型。 MapReduce 的基本原理是将一个复杂的问题（数据集）分成若干个简单的子问题（数据块）进行解决（ Map 函数）；然后对子问题的结果进行合并（ Reduce 函数），得到原有问题的解（结果）。

（课本摘要）

## 一、MapReduce编程模型





### 1、MapReduce编程模型简介

​     ManReduce 是一种思想或是一种编栓模型。
​     ManReduce 编程模型主要由两个抽象类构成， Mapper 用以对切分过的原始数据进行处理Reducer 则对 Mapper 的结果进行汇总，得到最后的输出结果对软件开发人员而言，只需要分别实现 Map 函数和 Reduce 函数即可以编写 MapReduce 程序，这一点和编写过程函数一样简单。
​     在数据格式上， Mapper 接受＜ key , value ＞格式的数据流，并产生一系列同样是＜ key , value >形式的输出，这些输出经过相应处理，形成＜ key ,{ value list }＞的形式的中间结果；之后，由 Mapper 产生的中间结果再传给 Reducer 作为输入，把相同 key 值的｛ value listy 做相应处理，最终生成＜ key , value ＞形式的结果数据，再写入 HDFS 中。根据其工作原理，可将 MapReduce 编程模型分为两类： MapReduce 简单模型和 MapReduce 复杂模型。

#### (1) MapReduce 简单模型

对于某些任务来说可能并不一定需要 Reduce 过程，如只需要对文本的每一行数据作简单的格式转换即可，那么只需要由 Mapper 处理后就可以了。所以 MapReduce 也有简单的编程馔型，该模型只有 Mapper 过程，由 Mapper 产生的数据直接写入 HDFS 。

#### (2) MapReduce 复杂模型

对于大部分的任务来说，都是需要 Reduce 过程，并且由于任务繁重，会启动多个Reducer （默认为1，根据任务量可由用户自己设定合适的 Reducer 数量）来进行汇总。如果只用一个 Reducer 计算所有 Mapper 的结果，会导致单个 Reducer 负载过于繁重，成为性能的颈，大大增加任务的运行周期。

###  2、MapReduce 编程实例

https://img-blog.csdn.net/20171023183600950?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhvbmdxaTI1MTM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center

## 二、 MapReduce 数据流

### 1、分片、格式化数据源（InputFormat）

InputFormat 主要有两个任务，一个是对源文件进行分片，并确定 Mapper 的数量：另一个是对各分片进行格式化，处理成＜ key , value ＞形式的数据流并传给 Mapper 。

### 2、Map过程

### 3、Combiner过程

### 4、Shuffle过程

### 5、Reduce过程

## 三、 MapReduce 任务运行流程

### 1、MRv2基本组成

#### （1）客户端（client）：用于Yarn集群提交任务；MapReduce与Yarn的唯一通讯途径。

#### （2）MRAPPMaster：负责任务管理。

#### （3）Map Task和Reduce Task:(Map\Reduce)通过用户定义两者比例，他们只能运行在Yarn给定的资源限定下。由MRAPPMaster\NodeManage协同管理和调用。

### 2、Yarn基本组成

Yarn 是一个资源管理平台，它监控和调度整个集群资源，并负责管理集群所有任务的运行和任务资源的分配

#### （1）Resource Manager（RM）

#### （2）NodeManage

#### （3）ApplicationsMaster

#### （4）Conter

### 3、任务流程

（1) client 向 ResourceManager 提交任务。

（2) ResourceManager 分配该任务的第一个 container ，并通知相应的 NodeManager 启动 MRAppMaster 。
（3) NodeManager 接收命令后，开辟一个 container 资源空间，并在 container 中启动相应的 MRAppMaster 。
（4) MRAppMaster 启动之后，第一步会向 ResourceManager 注册，这样用户可以直接通过 MRAppMaster 监控任务的运行状态；之后则直接由 MRAppaster 调度任务运行，重复5)~8)，直到任务结束。
（5) MRAppMaster 以轮询的方式向 ResourceManager 申请任务运行所需的资源。
（6）一旦 ResourceManager 配给了资源， MRAppMaster 便会与相应的 NodeManager 通信，让它划分 Container 并启动相应的任务（ MapTask 或 Reduce Task )。删除编辑
（7) NodeManager 准备好运行环境，启动任务。
（8）各任务运行，并定时通过 RPC 协议向 MRAppMaster 汇报自己的运行状态和进度。 MRAppMaster 也会实时地监控任务的运行，当发现某个 Task 假死或失败时，便杀死它重新眉动任务。
（9）任务完成， MRAppMaster 向 ResourceManager 通信，注销并关闭自己。

## 四、主要功能

### MapReduce提供了以下的主要功能：

#### （1）数据划分和计算任务调度：

系统自动将一个作业（Job）待处理的大数据划分为很多个数据块，每个数据块对应于一个计算任务（Task），并自动 调度计算节点来处理相应的数据块。作业和任务调度功能主要负责分配和调度计算节点（Map节点或Reduce节点），同时负责监控这些节点的执行状态，并 负责Map节点执行的同步控制。

#### （2）数据/代码互定位：

为了减少数据通信，一个基本原则是本地化数据处理，即一个计算节点尽可能处理其本地磁盘上所分布存储的数据，这实现了代码向 数据的迁移；当无法进行这种本地化数据处理时，再寻找其他可用节点并将数据从网络上传送给该节点（数据向代码迁移），但将尽可能从数据所在的本地机架上寻 找可用节点以减少通信延迟。

#### （3）系统优化：

为了减少数据通信开销，中间结果数据进入Reduce节点前会进行一定的合并处理；一个Reduce节点所处理的数据可能会来自多个 Map节点，为了避免Reduce计算阶段发生数据相关性，Map节点输出的中间结果需使用一定的策略进行适当的划分处理，保证相关性数据发送到同一个 Reduce节点；此外，系统还进行一些计算性能优化处理，如对最慢的计算任务采用多备份执行、选最快完成者作为结果。

#### （4）出错检测和恢复：

以低端商用服务器构成的大规模MapReduce计算集群中，节点硬件（主机、磁盘、内存等）出错和软件出错是常态，因此 MapReduce需要能检测并隔离出错节点，并调度分配新的节点接管出错节点的计算任务。同时，系统还将维护数据存储的可靠性，用多备份冗余存储机制提 高数据存储的可靠性，并能及时检测和恢复出错的数据。

## 五、主要技术特征

### MapReduce设计上具有以下主要的技术特征：

#### （1）向“外”横向扩展，而非向“上”纵向扩展

即MapReduce集群的构建完全选用价格便宜、易于扩展的低端商用服务器，而非价格昂贵、不易扩展的高端服务器。

对于大规模数据处理，由于有大 量数据存储需要，显而易见，基于低端服务器的集群远比基于高端服务器的集群优越，这就是为什么MapReduce并行计算集群会基于低端服务器实现的原 因。

#### （2）失效被认为是常态

MapReduce集群中使用大量的低端服务器，因此，节点硬件失效和软件出错是常态，因而一个良好设计、具有高容错性的[并行计算系统](https://baike.baidu.com/item/并行计算系统/19130839?fromModule=lemma_inlink)不能因为节点 失效而影响计算服务的质量，任何节点失效都不应当导致结果的不一致或不确定性；任何一个节点失效时，其他节点要能够无缝接管失效节点的计算任务；当失效节 点恢复后应能自动无缝加入集群，而不需要管理员人工进行系统配置。

MapReduce并行计算软件框架使用了多种有效的错误检测和恢复机制，如节点自动重 启技术，使集群和计算框架具有对付节点失效的健壮性，能有效处理失效节点的检测和恢复。

#### （3）把处理向数据迁移

传统高性能计算系统通常有很多处理器节点与一些外存储器节点相连，如用存储区域网络（Storage Area，SAN Network）连接的磁盘阵列，因此，大规模数据处理时外存文件数据I/O访问会成为一个制约系统性能的瓶颈。

为了减少大规模数据并行计算系统中的数据 通信开销，代之以把数据传送到处理节点（数据向处理器或代码迁移），应当考虑将处理向数据靠拢和迁移。MapReduce采用了数据/代码互定位的技术方法，计算节点将首先尽量负责计算其本地存储的数据，以发挥数据本地化特点，仅当节点无法处理本地数据时，再采用就近原则寻找其他可用计算节点，并把数据传送到该可用计算节点。

#### （4）顺序处理数据、避免随机访问数据

大规模数据处理的特点决定了大量的数据记录难以全部存放在内存，而通常只能放在外存中进行处理。由于磁盘的顺序访问要远比随机访问快得多，因此 MapReduce主要设计为面向顺序式大规模数据的磁盘访问处理。

为了实现面向大数据集批处理的高吞吐量的并行处理，MapReduce可以利用集群中 的大量数据存储节点同时访问数据，以此利用分布集群中大量节点上的磁盘集合提供高带宽的数据访问和传输。

#### （5）为应用开发者隐藏系统层细节

软件工程实践指南中，专业程序员认为之所以写程序困难，是因为程序员需要记住太多的编程细节（从变量名到复杂算法的边界情况处理），这对大脑记忆是 一个巨大的认知负担，需要高度集中注意力；而并行程序编写有更多困难，如需要考虑多线程中诸如同步等复杂繁琐的细节。由于并发执行中的不可预测性，程序的 调试查错也十分困难；而且，大规模数据处理时程序员需要考虑诸如数据分布存储管理、数据分发、数据通信和同步、计算结果收集等诸多细节问题。

MapReduce提供了一种抽象机制将程序员与系统层细节隔离开来，程序员仅需描述需要计算什么（What to compute），而具体怎么去计算（How to compute）就交由系统的执行框架处理，这样程序员可从系统层细节中解放出来，而致力于其应用本身计算问题的算法设计。

#### （6）平滑无缝的可扩展性

这里指出的可扩展性主要包括两层意义上的扩展性：数据扩展和系统规模扩展性。

理想的软件算法应当能随着数据规模的扩大而表现出持续的有效性，性能上的下降程度应与数据规模扩大的倍数相当；在集群规模上，要求算法的计算性能应能随着节点数的增加保持接近线性程度的增长。绝大多数现有的单机算法都达不到 以上理想的要求；把中间结果数据维护在内存中的单机算法在大规模数据处理时很快失效；从单机到基于大规模集群的并行计算从根本上需要完全不同的算法设计。奇妙的是，MapReduce在很多情形下能实现以上理想的扩展性特征。

多项研究发现，对于很多计算问题，基于MapReduce的计算性能可随节点数目增长保持近似于线性的增长。